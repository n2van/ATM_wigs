import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

import gradio as gr
from refacer import Refacer
import argparse
import ngrok
import imageio
import numpy as np
from PIL import Image
import tempfile
import base64
import pyfiglet
import shutil
import time
import torch
import torchvision
import torch.nn as nn
import torchvision.transforms as T

print("\033[94m" + pyfiglet.Figlet(font='slant').renderText("Development by Van Nguyen") + "\033[0m")

# Face Shape Predictor class from detection.py
class FaceShapePredictor:
    def __init__(self, model_path):
        # Kh·ªüi t·∫°o c√°c l·ªõp m·∫∑t
        self.class_names = ['Heart', 'Oblong', 'Oval', 'Round', 'Square']
        
        # T·∫£i model
        try:
            self.model = self.load_model(model_path)
            print("Face shape detection model loaded successfully!")
        except Exception as e:
            print(f"Error: Cannot load face shape model: {e}")
            self.model = None

    def load_model(self, model_path):
        # Kh·ªüi t·∫°o m√¥ h√¨nh
        model = torchvision.models.efficientnet_b4(pretrained=False)
        
        # Thay ƒë·ªïi l·ªõp classifier
        model.classifier = nn.Sequential(
            nn.Dropout(p=0.3, inplace=True),
            nn.Linear(model.classifier[1].in_features, len(self.class_names))
        )
        
        # T·∫£i tr·ªçng s·ªë t·ª´ file PTH
        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
        
        # Ch·∫ø ƒë·ªô evaluation
        model.eval()
        
        return model
    
    def predict(self, image_path):
        if not os.path.exists(image_path):
            print(f"Error: Image file '{image_path}' does not exist!")
            return None
        
        if self.model is None:
            return None
        
        try:
            # T·∫°o transform
            transform = T.Compose([
                T.Resize((224, 224)),
                T.ToTensor(),
                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
            
            # ƒê·ªçc v√† x·ª≠ l√Ω ·∫£nh
            image = Image.open(image_path).convert('RGB')
            input_tensor = transform(image).unsqueeze(0)
            
            # D·ª± ƒëo√°n
            with torch.no_grad():
                output = self.model(input_tensor)
                probabilities = torch.nn.functional.softmax(output, dim=1)[0]
                _, predicted = torch.max(output, 1)
            
            predicted_class = self.class_names[predicted.item()]
            confidence = probabilities[predicted.item()].item()
            
            # L·∫•y danh s√°ch x√°c su·∫•t c·ªßa t·∫•t c·∫£ c√°c l·ªõp
            probs = probabilities.cpu().numpy()
            
            return {
                "predicted_class": predicted_class,
                "confidence": confidence,
                "probabilities": {
                    self.class_names[i]: float(probs[i]) for i in range(len(self.class_names))
                }
            }
            
        except Exception as e:
            print(f"Error when predicting: {e}")
            return None

def cleanup_temp(folder_path):
    try:
        shutil.rmtree(folder_path)
        print("Gradio cache cleared successfully.")
    except Exception as e:
        print(f"Error: {e}")

# Prepare temp folder
os.environ["GRADIO_TEMP_DIR"] = "./tmp"
if os.path.exists("./tmp"):
    cleanup_temp(os.environ['GRADIO_TEMP_DIR'])
if not os.path.exists("./tmp"):
    os.makedirs("./tmp")

# T·∫°o th∆∞ m·ª•c ch·ª©a c√°c h√¨nh ·∫£nh m·∫´u n·∫øu ch∆∞a t·ªìn t·∫°i
if not os.path.exists("./example_wigs"):
    os.makedirs("./example_wigs")
    print("ƒê√£ t·∫°o th∆∞ m·ª•c 'example_wigs'. Vui l√≤ng th√™m c√°c h√¨nh ·∫£nh t√≥c gi·∫£ m·∫´u v√†o th∆∞ m·ª•c n√†y.")

# Default path for face shape detection model
DEFAULT_MODEL_PATH = "face_shape_model.pth"

# H√†m t·∫£i c√°c h√¨nh ·∫£nh t√≥c gi·∫£ m·∫´u
def load_example_wigs():
    example_wigs = []
    wig_folder = "./example_wigs"  # Th∆∞ m·ª•c ch·ª©a c√°c m·∫´u t√≥c gi·∫£
    
    if os.path.exists(wig_folder):
        for file in os.listdir(wig_folder):
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                example_wigs.append(os.path.join(wig_folder, file))
    
    # N·∫øu kh√¥ng t√¨m th·∫•y file n√†o, tr·∫£ v·ªÅ danh s√°ch tr·ªëng
    return example_wigs

# Parse arguments
parser = argparse.ArgumentParser(description='Refacer')
parser.add_argument("--max_num_faces", type=int, default=1)  # Changed from 8 to 1
parser.add_argument("--force_cpu", default=False, action="store_true")
parser.add_argument("--share_gradio", default=False, action="store_true")
parser.add_argument("--server_name", type=str, default="127.0.0.1")
parser.add_argument("--server_port", type=int, default=1221)
parser.add_argument("--colab_performance", default=False, action="store_true")
parser.add_argument("--ngrok", type=str, default=None)
parser.add_argument("--ngrok_region", type=str, default="us")
parser.add_argument("--face_shape_model", type=str, default=DEFAULT_MODEL_PATH)
args = parser.parse_args()

# Initialize
refacer = Refacer(force_cpu=args.force_cpu, colab_performance=args.colab_performance)
num_faces = args.max_num_faces  # This will now be 1

# Initialize face shape predictor
face_shape_predictor = FaceShapePredictor(args.face_shape_model)

def create_dummy_image():
    dummy = Image.new('RGB', (1, 1), color=(255, 255, 255))
    temp_file = tempfile.NamedTemporaryFile(delete=False, dir="./tmp", suffix=".png")
    dummy.save(temp_file.name)
    return temp_file.name

def load_image_from_path(image_path):
    """Load an image from a file path and return a numpy array."""
    if image_path is None:
        return None
    
    if not os.path.exists(image_path):
        print(f"File kh√¥ng t·ªìn t·∫°i: {image_path}")
        return None
    
    try:
        # ƒê·ªçc h√¨nh ·∫£nh b·∫±ng PIL
        image = Image.open(image_path).convert('RGB')
        # Chuy·ªÉn ƒë·ªïi sang numpy array
        image_array = np.array(image)
        return image_array
    except Exception as e:
        print(f"L·ªói khi ƒë·ªçc h√¨nh ·∫£nh {image_path}: {e}")
        return None

def run_image(image_path, face_path):
    print(f"START run_image with: image_path={image_path}, face_path={face_path}")
    
    # Ki·ªÉm tra ƒë·∫ßu v√†o
    if image_path is None or face_path is None:
        print("image_path ho·∫∑c face_path l√† None")
        return None
    
    # ƒê·∫£m b·∫£o c·∫£ hai ƒë·ªÅu l√† ƒë∆∞·ªùng d·∫´n file h·ª£p l·ªá
    if not os.path.exists(image_path) or not os.path.exists(face_path):
        print(f"File kh√¥ng t·ªìn t·∫°i: image_path={image_path}, face_path={face_path}")
        return None
    
    # L∆∞u ·∫£nh k·∫øt qu·∫£ v√†o file t·∫°m
    timestamp = int(time.time() * 1000)
    output_path = os.path.join("./tmp", f"result_{timestamp}.png")
    
    # Th√¥ng s·ªë cho x·ª≠ l√Ω ·∫£nh
    disable_similarity = True
    multiple_faces_mode = False
    partial_reface_ratio = 0.0
    
    # T·∫°o danh s√°ch faces cho refacer
    faces = [{
        'origin': None,
        'destination': face_path,
        'threshold': 0.0
    }]
    
    print(f"Created faces array: {faces}")
    
    try:
        # M·ªü v√† ƒë·ªçc file ·∫£nh b·∫±ng PIL tr∆∞·ªõc khi x·ª≠ l√Ω
        wig_img = Image.open(image_path).convert('RGB')
        wig_array = np.array(wig_img)
        face_img = Image.open(face_path).convert('RGB')
        face_array = np.array(face_img)
        
        print(f"Loaded wig image shape: {wig_array.shape}")
        print(f"Loaded face image shape: {face_array.shape}")
        
        # L∆∞u t·∫°m c√°c ·∫£nh ƒë√£ x·ª≠ l√Ω
        temp_wig_path = os.path.join("./tmp", f"temp_wig_{timestamp}.png")
        temp_face_path = os.path.join("./tmp", f"temp_face_{timestamp}.png")
        wig_img.save(temp_wig_path)
        face_img.save(temp_face_path)
        
        # C·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n cho faces
        faces[0]['destination'] = temp_face_path
        
        print("Calling refacer.reface_image...")
        
        # G·ªçi h√†m reface_image v·ªõi ƒë∆∞·ªùng d·∫´n t·∫°m th·ªùi
        result = refacer.reface_image(
            temp_wig_path, 
            faces, 
            disable_similarity=disable_similarity,
            multiple_faces_mode=multiple_faces_mode,
            partial_reface_ratio=partial_reface_ratio
        )
        
        print(f"Result type: {type(result)}")
        
        # X·ª≠ l√Ω k·∫øt qu·∫£
        if result is not None:
            if isinstance(result, str) and os.path.exists(result):
                print(f"Returning result path: {result}")
                return result
            elif isinstance(result, np.ndarray):
                print(f"Saving numpy array to {output_path}")
                Image.fromarray(result).save(output_path)
                return output_path
            else:
                print(f"Unexpected result type: {type(result)}")
        else:
            print("Result is None")
        
        return None
    except Exception as e:
        print(f"L·ªói trong run_image: {e}")
        import traceback
        traceback.print_exc()
        return None

def detect_face_shape(image_path):
    print(f"START detect_face_shape with: image_path={image_path}")
    
    if image_path is None:
        print("No face uploaded")
        return "No face uploaded"
    
    if not os.path.exists(image_path):
        print(f"File kh√¥ng t·ªìn t·∫°i: {image_path}")
        return "File kh√¥ng t·ªìn t·∫°i"
    
    try:
        # ƒê·∫£m b·∫£o image_path l√† ƒë∆∞·ªùng d·∫´n h·ª£p l·ªá
        result = face_shape_predictor.predict(image_path)
        if result is None:
            print("Kh√¥ng th·ªÉ nh·∫≠n di·ªán h√¨nh d·∫°ng khu√¥n m·∫∑t")
            return "Kh√¥ng th·ªÉ nh·∫≠n di·ªán h√¨nh d·∫°ng khu√¥n m·∫∑t"
        
        # Format the result
        face_shape = result["predicted_class"]
        confidence = result["confidence"] * 100
        
        output_text = f"Detected Face Shape: {face_shape} ({confidence:.1f}%)\n\n"
        output_text += "Probability Breakdown:\n"
        
        for shape, prob in result["probabilities"].items():
            output_text += f"- {shape}: {prob*100:.1f}%\n"
        
        print(f"Face shape detection result: {face_shape}")
        return output_text
    except Exception as e:
        print(f"L·ªói trong detect_face_shape: {e}")
        import traceback
        traceback.print_exc()
        return f"L·ªói khi nh·∫≠n di·ªán: {str(e)}"

def load_first_frame(filepath):
    if filepath is None:
        return None
    frames = imageio.get_reader(filepath)
    return frames.get_data(0)

def extract_faces_auto(filepath, refacer_instance, max_faces=1, isvideo=False):
    if filepath is None:
        return [None] * max_faces

    if isvideo and os.path.getsize(filepath) > 5 * 1024 * 1024:
        print("Video too large for auto-extract, skipping face extraction.")
        return [None] * max_faces

    frame = load_first_frame(filepath)
    if frame is None:
        return [None] * max_faces

    while len(frame.shape) > 3:
        frame = frame[0]

    if frame.shape[-1] != 3:
        raise ValueError(f"Expected last dimension to be 3 (RGB), but got {frame.shape[-1]}")

    temp_image_path = os.path.join("./tmp", f"temp_face_extract_{int(time.time() * 1000)}.png")
    Image.fromarray(frame).save(temp_image_path)

    try:
        faces = refacer_instance.extract_faces_from_image(temp_image_path, max_faces=max_faces)
        result = faces + [None] * (max_faces - len(faces))
        return result
    finally:
        if os.path.exists(temp_image_path):
            try:
                os.remove(temp_image_path)
            except Exception as e:
                print(f"Warning: Could not delete temp file {temp_image_path}: {e}")

# Simplified for single face
def distribute_faces(filepath):
    faces = extract_faces_auto(filepath, refacer, max_faces=1)
    return faces[0]

# H√†m load wig example ƒë·ªÉ hi·ªÉn th·ªã trong Select Wigs
def load_wig_example(example_path):
    return example_path

# Check if face shape and image match - returns recommendation
def get_wig_recommendation(face_shape_text):
    print(f"START get_wig_recommendation with: {face_shape_text}")
    
    if face_shape_text is None or face_shape_text == "No face uploaded" or face_shape_text == "File kh√¥ng t·ªìn t·∫°i" or face_shape_text == "Kh√¥ng th·ªÉ nh·∫≠n di·ªán h√¨nh d·∫°ng khu√¥n m·∫∑t":
        return "Vui l√≤ng t·∫£i l√™n ·∫£nh khu√¥n m·∫∑t ƒë·ªÉ nh·∫≠n g·ª£i √Ω t√≥c gi·∫£ ph√π h·ª£p."
    
    # Tr√≠ch xu·∫•t h√¨nh d·∫°ng khu√¥n m·∫∑t t·ª´ vƒÉn b·∫£n ph√°t hi·ªán
    try:
        if "Detected Face Shape:" in face_shape_text:
            shape = face_shape_text.split("Detected Face Shape:")[1].split("(")[0].strip()
            print(f"Extracted face shape: {shape}")
        else:
            print("Kh√¥ng th·ªÉ x√°c ƒë·ªãnh h√¨nh d·∫°ng khu√¥n m·∫∑t t·ª´ k·∫øt qu·∫£ nh·∫≠n di·ªán")
            return "Kh√¥ng th·ªÉ x√°c ƒë·ªãnh h√¨nh d·∫°ng khu√¥n m·∫∑t t·ª´ k·∫øt qu·∫£ nh·∫≠n di·ªán."
        
        recommendations = {
            "Heart": "ƒê·ªëi v·ªõi khu√¥n m·∫∑t tr√°i tim, h√£y th·ª≠ t√≥c gi·∫£ c√≥ ki·ªÉu t√≥c x·∫øp l·ªõp gi√∫p tƒÉng ƒë·ªô r·ªông ·ªü v√πng x∆∞∆°ng h√†m. Ki·ªÉu t√≥c d√†i v·ª´a ph·∫£i v·ªõi t√≥c m√°i r·∫Ω m·ªôt b√™n ho·∫°t ƒë·ªông r·∫•t t·ªët.",
            "Oblong": "ƒê·ªëi v·ªõi khu√¥n m·∫∑t thu√¥n d√†i, h√£y c√¢n nh·∫Øc t√≥c gi·∫£ c√≥ ƒë·ªô ph·ªìng ·ªü hai b√™n ƒë·ªÉ t·∫°o ƒë·ªô r·ªông. Tr√°nh ki·ªÉu t√≥c qu√° d√†i v√† h√£y th·ª≠ ki·ªÉu t√≥c c√≥ m√°i ƒë·ªÉ r√∫t ng·∫Øn khu√¥n m·∫∑t.",
            "Oval": "ƒê·ªëi v·ªõi khu√¥n m·∫∑t oval, h·∫ßu h·∫øt c√°c ki·ªÉu t√≥c gi·∫£ ƒë·ªÅu ph√π h·ª£p! B·∫°n c√≥ h√¨nh d·∫°ng khu√¥n m·∫∑t ƒëa nƒÉng ph√π h·ª£p v·ªõi m·ªçi ƒë·ªô d√†i ho·∫∑c phong c√°ch.",
            "Round": "ƒê·ªëi v·ªõi khu√¥n m·∫∑t tr√≤n, h√£y th·ª≠ t√≥c gi·∫£ c√≥ ki·ªÉu t√≥c x·∫øp l·ªõp ho·∫∑c b·∫•t ƒë·ªëi x·ª©ng ƒë·ªÉ tƒÉng chi·ªÅu cao. T√≥c gi·∫£ d√†i h∆°n v·ªõi c√°c l·ªõp xung quanh khu√¥n m·∫∑t gi√∫p k√©o d√†i khu√¥n m·∫∑t.",
            "Square": "ƒê·ªëi v·ªõi khu√¥n m·∫∑t vu√¥ng, t√≥c gi·∫£ m·ªÅm m·∫°i v·ªõi c√°c l·ªõp xung quanh khu√¥n m·∫∑t ho·∫°t ƒë·ªông r·∫•t t·ªët. H√£y th·ª≠ ki·ªÉu t√≥c c√≥ m√°i r·∫Ω m·ªôt b√™n v√† tr√°nh ki·ªÉu t√≥c bob c·∫Øt th·∫≥ng."
        }
        
        if shape in recommendations:
            return recommendations[shape]
        else:
            return "Kh√¥ng c√≥ g·ª£i √Ω c·ª• th·ªÉ cho h√¨nh d·∫°ng khu√¥n m·∫∑t n√†y."
    except Exception as e:
        print(f"L·ªói trong get_wig_recommendation: {e}")
        import traceback
        traceback.print_exc()
        return "ƒê√£ x·∫£y ra l·ªói khi t·∫°o g·ª£i √Ω t√≥c gi·∫£."

# --- UI v·ªõi CSS t√πy ch·ªânh ---
custom_css = """
body {
    background-color: #f8fafc;
    color: #1e293b;
}

.gradio-container {
    max-width: 1400px !important;
    margin: 0 auto;
    background-color: #ffffff;
    border-top: 5px solid #0e1b4d; /* Ch·ªâ vi·ªÅn tr√™n v·ªõi m√†u xanh navy */
    border-radius: 10px;
    box-shadow: 0 3px 20px rgba(14, 27, 77, 0.1);
    padding: 25px;
}

.header-container {
    padding: 20px;
    margin-bottom: 20px;
    background-color: #0e1b4d;
    color: white;
    border-radius: 10px;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    display: flex;
    align-items: center;
}

.header-logo {
    margin-right: 20px; /* Kho·∫£ng c√°ch gi·ªØa logo v√† text */
}

.header-text {
    flex: 1;
}

.header-title {
    font-size: 2.5rem;
    font-weight: bold;
    color: white;
    margin-bottom: 5px;
    text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
}

.header-subtitle {
    font-size: 1.2rem;
    color: #bfdbfe;
}

.input-panel {
    background-color: #6194c7;
    border-radius: 10px;
    padding: 15px;
    margin-bottom: 15px;
    border: 1px solid #e2e8f0;
}

.output-panel {
    background-color: #6194c7;
    border-radius: 10px;
    padding: 15px;
    border: 1px solid #e2e8f0;
    margin: 0 auto; /* Gi√∫p cƒÉn gi·ªØa panel */
    max-width: 800px; /* Gi·ªõi h·∫°n chi·ªÅu r·ªông khi ƒë·ª©ng m·ªôt m√¨nh */
}

.detection-panel {
    background-color: #e6f0ff;
    border-radius: 10px;
    padding: 15px;
    border: 1px solid #a0c8ff;
    margin-top: 15px;
}

.recommendation-panel {
    background-color: #f0f9ff;
    border-radius: 10px;
    padding: 15px;
    border: 1px solid #bae6fd;
    margin-top: 10px;
}

.control-panel {
    border-radius: 10px;
    padding: 15px;
    margin: 15px 0;
    border: 1px solid #e2e8f0;
    text-align: center;
}

.face-container {
    background-color: #6194c7;
    border-radius: 8px;
    padding: 10px;
    border: 1px solid #e2e8f0;
    margin-bottom: 10px;
}

.section-title {
    font-weight: bold;
    font-size: 1.2rem;
    margin-bottom: 10px;
    color: #0e1b4d; /* Gi·ªØ nguy√™n m√†u ch·ªØ xanh navy ƒë·∫≠m */
    padding: 5px 10px; /* Th√™m padding ƒë·ªÉ t·∫°o kh√¥ng gian cho khung */
    border: 2px solid #a0c8ff; /* Khung m√†u xanh d∆∞∆°ng nh·∫°t */
    border-radius: 5px; /* Bo tr√≤n g√≥c khung */
    background-color: #e6f0ff; /* N·ªÅn xanh d∆∞∆°ng r·∫•t nh·∫°t */
    display: inline-block;
}

.footer {
    text-align: center;
    margin-top: 40px;
    padding: 20px;
    border-top: 1px solid #e2e8f0;
    font-size: 0.9rem;
    color: #1e293b;
    opacity: 0.7;
}

/* CSS cho gallery h√¨nh ·∫£nh m·∫´u */
.example-gallery {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(120px, 1fr));
    gap: 10px;
    margin-top: 10px;
}

.example-item {
    cursor: pointer;
    border-radius: 5px;
    overflow: hidden;
    border: 2px solid transparent;
    transition: all 0.2s ease;
}

.example-item:hover {
    transform: scale(1.05);
    border-color: #0e1b4d;
    box-shadow: 0 0 10px rgba(14, 27, 77, 0.3);
}

.example-item img {
    width: 100%;
    height: 100px;
    object-fit: cover;
}

/* Th√™m m√†u s·∫Øc navy cho c√°c n√∫t */
button.primary {
    background-color: #0e1b4d !important;
}

button.primary:hover {
    background-color: #1a2e6c !important;
}
"""

# S·ª≠ d·ª•ng theme ƒë∆°n gi·∫£n cho c√°c phi√™n b·∫£n Gradio c≈©
theme = gr.themes.Base(primary_hue="blue", secondary_hue="blue")

with gr.Blocks(theme=theme, css=custom_css, title="ATMwigs - Try-on Wigs") as demo:
    # Logo and Header
    try:
        with open("Logo.png", "rb") as f:
            icon_data = base64.b64encode(f.read()).decode()
        icon_html = f'<img src="data:image/png;base64,{icon_data}" style="width:100px;height:100px;">'
    except FileNotFoundError:
        icon_html = '<div style="font-size: 3rem; color: white;">üíá</div>'
    
    gr.HTML(f"""
    <div class="header-container">
        <div class="header-logo">{icon_html}</div>
        <div class="header-text">
            <div class="header-title">ATMwigs</div>
            <div class="header-subtitle">Virtual Try-on System for Wigs</div>
        </div>
    </div>
    """)

    # --- IMAGE MODE ---
    with gr.Tab("Image Mode"):
        # H√†ng ƒë·∫ßu ti√™n: Original Face v√† Select Wigs
        with gr.Row():
            # Input Column - Face
            with gr.Column(scale=1, elem_classes="face-container"):
                gr.Markdown('<div class="section-title">Original Face</div>')
                dest_img = gr.Image(label="Input Face", height=400, type="filepath")
                
                # Add face detection button
                detect_btn = gr.Button("Detect Face Shape", variant="primary")
                
                # Output for face shape detection
                with gr.Column(elem_classes="detection-panel"):
                    face_shape_output = gr.Textbox(label="Face Shape Detection", lines=8)
                
                # Recommendations based on face shape
                with gr.Column(elem_classes="recommendation-panel"):
                    recommendation_output = gr.Textbox(label="Recommended Wig Styles", lines=4)
            
            # Input Column - Wigs
            with gr.Column(scale=1, elem_classes="input-panel"):
                gr.Markdown('<div class="section-title">Wigs</div>')
                image_input = gr.Image(label="Select Wigs", type="filepath", height=400)
                
                # Hi·ªÉn th·ªã h√¨nh ·∫£nh t√≥c gi·∫£ m·∫´u
                example_wigs = load_example_wigs()
                if example_wigs:
                    gr.Markdown('<div class="section-title">Example Wigs</div>')
                    with gr.Row(elem_classes="example-gallery"):
                        for wig in example_wigs:
                            wig_btn = gr.Button(
                                "",
                                elem_classes="example-item"
                            )
                            wig_btn.style(
                                full_width=False,
                                size="sm",
                                image=wig
                            )
                            # Khi nh·∫•p v√†o m·ªôt h√¨nh ·∫£nh m·∫´u, load h√¨nh ·∫£nh ƒë√≥ v√†o √¥ select wig
                            wig_btn.click(
                                fn=load_wig_example,
                                inputs=[],
                                outputs=[image_input],
                                _js=f"() => '{wig}'"
                            )
        
        # H√†ng th·ª© hai: N√∫t Try On Wig
        with gr.Row(elem_classes="control-panel"):
            image_btn = gr.Button("Try On Wig", variant="primary", size="lg")
        
        # H√†ng th·ª© ba: Result
        with gr.Row():
            # Output Column - ·ªû gi·ªØa ƒë·ªÉ c√¢n b·∫±ng giao di·ªán
            with gr.Column(scale=1, elem_classes="output-panel"):
                gr.Markdown('<div class="section-title">Result</div>')
                image_output = gr.Image(label="After try-on", interactive=False, type="filepath", height=400)
        
        # Connect events - simplified for just one wig
        image_btn.click(
            fn=run_image,
            inputs=[image_input, dest_img],
            outputs=image_output
        )
        
        # Connect face detection
        detect_btn.click(
            fn=detect_face_shape,
            inputs=[dest_img],
            outputs=[face_shape_output]
        )
        
        # Connect recommendation generation
        detect_btn.click(
            fn=get_wig_recommendation,
            inputs=[face_shape_output],
            outputs=[recommendation_output]
        )

    # Footer
    gr.HTML("""
    <div class="footer">
        <p>¬© 2023 ATMwigs - All rights reserved</p>
        <p>Developed with ‚ù§Ô∏è for virtual wig try-on</p>
    </div>
    """)

# --- ngrok connect (optional) ---
if args.ngrok and args.ngrok != "None":
    def connect(token, port, options):
        try:
            public_url = ngrok.connect(f"127.0.0.1:{port}", **options).url()
            print(f'ngrok URL: {public_url}')
        except Exception as e:
            print(f'ngrok connection aborted: {e}')

    connect(args.ngrok, args.server_port, {'region': args.ngrok_region, 'authtoken_from_env': False})

# --- Launch app ---
if __name__ == "__main__":
    # Lo·∫°i b·ªè tham s·ªë enable_api v√¨ kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£ trong phi√™n b·∫£n c≈©
    demo.queue().launch(
        favicon_path="Logo.png" if os.path.exists("Logo.png") else None,
        show_error=True,
        share=args.share_gradio,
        server_name=args.server_name,
        server_port=args.server_port
    )
    
    # N·∫øu c·∫ßn t∆∞∆°ng th√≠ch API, h√£y th√™m message ƒë·ªÉ h∆∞·ªõng d·∫´n upgrade Gradio
    print("NOTE: To enable API functionality, upgrade Gradio to version 3.32.0 or higher.")
